<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Inseung Kang</title>
  
  <meta name="author" content="Inseung Kang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
<!--   <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Inseung Kang</name>
              </p>
              <p>Hi! I'm Inseung Kang, a PhD candidate in school of mechanical engineering at Georgia Institute of Technology. I work with Dr. Aaron J. Young at <a href="https://epic.gatech.edu">Exoskeleton and Prosthetic Intelligent Controls (EPIC) Lab</a> on developing a robotic hip exoskeleton to help people move better! My research portfolio is pretty diverse ranging from designing a versatile mechatronic hardware to developing a robust machine learning algorithms. Using these research tools, my main focus is to develop a smart robotic platform to enhance human mobility encompassed by both robust mechanical design and an intellectual controller. My long term research goal is to translate this wearable technology to a clinical population to help patients with gait deficiencies such as stroke, SCI, and muscular dystrophy!
              </p>
              <p style="text-align:center">
                <a href="mailto:ikang7@gatech.edu.com">Email</a> &nbsp/&nbsp
                <a href="data/InseungKang_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=jcgAPTYAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/inseung-kang-1632a4b1/">Linkedin</a> &nbsp/&nbsp
                <a href="https://twitter.com/inseungkang">Twitter</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/InseungKang.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/InseungKang.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in Exoskeleton, Robotics, Machine Learning, Optimization, and Biomechanics. Much of my research is about exploring how to optimize exoskeleton assistance through understanding the physical human robot interaction. Mainly, I tackle these research questions by developing advanced inferences to estimate and predict the user's intent (such as ambulation mode and walking speed) during dynamic locomotion and provide correpsonding exoskeleton assistance.
              </p>
            </td>
          </tr>

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
              <p>
                I'm interested in Exoskeleton, Robotics, Machine Learning, Optimization, and Biomechanics. Much of my research is about exploring how to optimize exoskeleton assistance through understanding the physical human robot interaction. Mainly, I tackle these research questions by developing advanced inferences to estimate and predict the user's intent (such as ambulation mode and walking speed) during dynamic locomotion and provide correpsonding exoskeleton assistance.
              </p>
            </td>
          </tr>

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
<!--             <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/lion_ff.jpg' width="160"></div>
                <img src='images/lion_none.jpg' width="160">
              </div>
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td> -->
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://people.eecs.berkeley.edu/~bmild/fourfeat/index.html">
                <papertitle>Investigating the Impact of the User Interface for a Powered Hip Orthosis on Metabolic Cost and User Comfort: A Preliminary Study</papertitle>
              </a>
              <br>
              <a>Seung Eun Lee, Claire Kilpatrick, <strong>Inseung Kang</strong>, Hsiang Hsu, Lee Childers, Aaron Young</a>
              <br>
        <em>Journal of Prosthetics and Orthotics</em>, 2020  
              <br>
              <a href="https://www.google.com/">PDF</a>
              <p></p>
              <p>AAA</p>
            </td>
          </tr> 

    
<!--           <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/vase_small.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/vase_still.png' width="160">
              </div>
              <script type="text/javascript">
                function nerf_start() {
                  document.getElementById('nerf_image').style.opacity = "1";
                }

                function nerf_stop() {
                  document.getElementById('nerf_image').style.opacity = "0";
                }
                nerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://www.matthewtancik.com/nerf">
                <papertitle>NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis</papertitle>
              </a>
              <br>
              <a href="https://people.eecs.berkeley.edu/~bmild/">Ben Mildenhall*</a>,
              <a href="https://people.eecs.berkeley.edu/~pratul/">Pratul Srinivasan*</a>,
              <a href="http://matthewtancik.com/">Matthew Tancik*</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>,
              <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a>
              <br>
              <em>ECCV</em>, 2020 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="http://www.matthewtancik.com/nerf">project page</a>
              /
              <a href="https://arxiv.org/abs/2003.08934">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=JuH79E8rdKc">video</a>
              /
              <a href="https://github.com/bmild/nerf">code</a>
              <p></p>
              <p>
              Training a tiny non-convolutional neural network to reproduce a scene using volume rendering achieves photorealistic view synthesis.</p>
            </td>
          </tr>  -->

        
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
             
                <br>
                <a href="https://jonbarron.info/">Cloned from this template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
